{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute_1</th>\n",
       "      <th>Attribute_2</th>\n",
       "      <th>Attribute_3</th>\n",
       "      <th>Attribute_4</th>\n",
       "      <th>Attribute_5</th>\n",
       "      <th>Attribute_6</th>\n",
       "      <th>Attribute_7</th>\n",
       "      <th>Attribute_8</th>\n",
       "      <th>Attribute_9</th>\n",
       "      <th>Attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute_52</th>\n",
       "      <th>Attribute_53</th>\n",
       "      <th>Attribute_54</th>\n",
       "      <th>Attribute_55</th>\n",
       "      <th>Attribute_56</th>\n",
       "      <th>Attribute_57</th>\n",
       "      <th>Attribute_58</th>\n",
       "      <th>Attribute_59</th>\n",
       "      <th>Attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute_1  Attribute_2  Attribute_3  Attribute_4  Attribute_5  \\\n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954   \n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   Attribute_6  Attribute_7  Attribute_8  Attribute_9  Attribute_10  ...  \\\n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   Attribute_52  Attribute_53  Attribute_54  Attribute_55  Attribute_56  \\\n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "\n",
       "   Attribute_57  Attribute_58  Attribute_59  Attribute_60  Class  \n",
       "0        0.0180        0.0084        0.0090        0.0032      R  \n",
       "1        0.0140        0.0049        0.0052        0.0044      R  \n",
       "2        0.0316        0.0164        0.0095        0.0078      R  \n",
       "3        0.0050        0.0044        0.0040        0.0117      R  \n",
       "4        0.0072        0.0048        0.0107        0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('sonar_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attribute_1     0\n",
       "Attribute_2     0\n",
       "Attribute_3     0\n",
       "Attribute_4     0\n",
       "Attribute_5     0\n",
       "Attribute_6     0\n",
       "Attribute_7     0\n",
       "Attribute_8     0\n",
       "Attribute_9     0\n",
       "Attribute_10    0\n",
       "Attribute_11    0\n",
       "Attribute_12    0\n",
       "Attribute_13    0\n",
       "Attribute_14    0\n",
       "Attribute_15    0\n",
       "Attribute_16    0\n",
       "Attribute_17    0\n",
       "Attribute_18    0\n",
       "Attribute_19    0\n",
       "Attribute_20    0\n",
       "Attribute_21    0\n",
       "Attribute_22    0\n",
       "Attribute_23    0\n",
       "Attribute_24    0\n",
       "Attribute_25    0\n",
       "Attribute_26    0\n",
       "Attribute_27    0\n",
       "Attribute_28    0\n",
       "Attribute_29    0\n",
       "Attribute_30    0\n",
       "               ..\n",
       "Attribute_32    0\n",
       "Attribute_33    0\n",
       "Attribute_34    0\n",
       "Attribute_35    0\n",
       "Attribute_36    0\n",
       "Attribute_37    0\n",
       "Attribute_38    0\n",
       "Attribute_39    0\n",
       "Attribute_40    0\n",
       "Attribute_41    0\n",
       "Attribute_42    0\n",
       "Attribute_43    0\n",
       "Attribute_44    0\n",
       "Attribute_45    0\n",
       "Attribute_46    0\n",
       "Attribute_47    0\n",
       "Attribute_48    0\n",
       "Attribute_49    0\n",
       "Attribute_50    0\n",
       "Attribute_51    0\n",
       "Attribute_52    0\n",
       "Attribute_53    0\n",
       "Attribute_54    0\n",
       "Attribute_55    0\n",
       "Attribute_56    0\n",
       "Attribute_57    0\n",
       "Attribute_58    0\n",
       "Attribute_59    0\n",
       "Attribute_60    0\n",
       "Class           0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute_1</th>\n",
       "      <th>Attribute_2</th>\n",
       "      <th>Attribute_3</th>\n",
       "      <th>Attribute_4</th>\n",
       "      <th>Attribute_5</th>\n",
       "      <th>Attribute_6</th>\n",
       "      <th>Attribute_7</th>\n",
       "      <th>Attribute_8</th>\n",
       "      <th>Attribute_9</th>\n",
       "      <th>Attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute_51</th>\n",
       "      <th>Attribute_52</th>\n",
       "      <th>Attribute_53</th>\n",
       "      <th>Attribute_54</th>\n",
       "      <th>Attribute_55</th>\n",
       "      <th>Attribute_56</th>\n",
       "      <th>Attribute_57</th>\n",
       "      <th>Attribute_58</th>\n",
       "      <th>Attribute_59</th>\n",
       "      <th>Attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Attribute_1  Attribute_2  Attribute_3  Attribute_4  Attribute_5  \\\n",
       "count   208.000000   208.000000   208.000000   208.000000   208.000000   \n",
       "mean      0.029164     0.038437     0.043832     0.053892     0.075202   \n",
       "std       0.022991     0.032960     0.038428     0.046528     0.055552   \n",
       "min       0.001500     0.000600     0.001500     0.005800     0.006700   \n",
       "25%       0.013350     0.016450     0.018950     0.024375     0.038050   \n",
       "50%       0.022800     0.030800     0.034300     0.044050     0.062500   \n",
       "75%       0.035550     0.047950     0.057950     0.064500     0.100275   \n",
       "max       0.137100     0.233900     0.305900     0.426400     0.401000   \n",
       "\n",
       "       Attribute_6  Attribute_7  Attribute_8  Attribute_9  Attribute_10  ...  \\\n",
       "count   208.000000   208.000000   208.000000   208.000000    208.000000  ...   \n",
       "mean      0.104570     0.121747     0.134799     0.178003      0.208259  ...   \n",
       "std       0.059105     0.061788     0.085152     0.118387      0.134416  ...   \n",
       "min       0.010200     0.003300     0.005500     0.007500      0.011300  ...   \n",
       "25%       0.067025     0.080900     0.080425     0.097025      0.111275  ...   \n",
       "50%       0.092150     0.106950     0.112100     0.152250      0.182400  ...   \n",
       "75%       0.134125     0.154000     0.169600     0.233425      0.268700  ...   \n",
       "max       0.382300     0.372900     0.459000     0.682800      0.710600  ...   \n",
       "\n",
       "       Attribute_51  Attribute_52  Attribute_53  Attribute_54  Attribute_55  \\\n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000   \n",
       "mean       0.016069      0.013420      0.010709      0.010941      0.009290   \n",
       "std        0.012008      0.009634      0.007060      0.007301      0.007088   \n",
       "min        0.000000      0.000800      0.000500      0.001000      0.000600   \n",
       "25%        0.008425      0.007275      0.005075      0.005375      0.004150   \n",
       "50%        0.013900      0.011400      0.009550      0.009300      0.007500   \n",
       "75%        0.020825      0.016725      0.014900      0.014500      0.012100   \n",
       "max        0.100400      0.070900      0.039000      0.035200      0.044700   \n",
       "\n",
       "       Attribute_56  Attribute_57  Attribute_58  Attribute_59  Attribute_60  \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \n",
       "mean       0.008222      0.007820      0.007949      0.007941      0.006507  \n",
       "std        0.005736      0.005785      0.006470      0.006181      0.005031  \n",
       "min        0.000400      0.000300      0.000300      0.000100      0.000600  \n",
       "25%        0.004400      0.003700      0.003600      0.003675      0.003100  \n",
       "50%        0.006850      0.005950      0.005800      0.006400      0.005300  \n",
       "75%        0.010575      0.010425      0.010350      0.010325      0.008525  \n",
       "max        0.039400      0.035500      0.044000      0.036400      0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attribute_1     float64\n",
       "Attribute_2     float64\n",
       "Attribute_3     float64\n",
       "Attribute_4     float64\n",
       "Attribute_5     float64\n",
       "Attribute_6     float64\n",
       "Attribute_7     float64\n",
       "Attribute_8     float64\n",
       "Attribute_9     float64\n",
       "Attribute_10    float64\n",
       "Attribute_11    float64\n",
       "Attribute_12    float64\n",
       "Attribute_13    float64\n",
       "Attribute_14    float64\n",
       "Attribute_15    float64\n",
       "Attribute_16    float64\n",
       "Attribute_17    float64\n",
       "Attribute_18    float64\n",
       "Attribute_19    float64\n",
       "Attribute_20    float64\n",
       "Attribute_21    float64\n",
       "Attribute_22    float64\n",
       "Attribute_23    float64\n",
       "Attribute_24    float64\n",
       "Attribute_25    float64\n",
       "Attribute_26    float64\n",
       "Attribute_27    float64\n",
       "Attribute_28    float64\n",
       "Attribute_29    float64\n",
       "Attribute_30    float64\n",
       "                 ...   \n",
       "Attribute_32    float64\n",
       "Attribute_33    float64\n",
       "Attribute_34    float64\n",
       "Attribute_35    float64\n",
       "Attribute_36    float64\n",
       "Attribute_37    float64\n",
       "Attribute_38    float64\n",
       "Attribute_39    float64\n",
       "Attribute_40    float64\n",
       "Attribute_41    float64\n",
       "Attribute_42    float64\n",
       "Attribute_43    float64\n",
       "Attribute_44    float64\n",
       "Attribute_45    float64\n",
       "Attribute_46    float64\n",
       "Attribute_47    float64\n",
       "Attribute_48    float64\n",
       "Attribute_49    float64\n",
       "Attribute_50    float64\n",
       "Attribute_51    float64\n",
       "Attribute_52    float64\n",
       "Attribute_53    float64\n",
       "Attribute_54    float64\n",
       "Attribute_55    float64\n",
       "Attribute_56    float64\n",
       "Attribute_57    float64\n",
       "Attribute_58    float64\n",
       "Attribute_59    float64\n",
       "Attribute_60    float64\n",
       "Class            object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=df.iloc[:,:-1]\n",
    "df_y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(df_y)\n",
    "y=le.transform(df_y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(df_x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 60)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 60)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg=LogisticRegression()\n",
    "lg.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=lg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      "Accuracy Score: 0.8253968253968254\n",
      "Confusion Matrix: [[32  3]\n",
      " [ 8 20]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        35\n",
      "           1       0.87      0.71      0.78        28\n",
      "\n",
      "    accuracy                           0.83        63\n",
      "   macro avg       0.83      0.81      0.82        63\n",
      "weighted avg       0.83      0.83      0.82        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print('Accuracy Score:', accuracy_score(test_y,pred))\n",
    "print('Confusion Matrix:', confusion_matrix(test_y,pred))   \n",
    "print('Classification Report:', classification_report(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accracy_score corresponding to random state:  42  is:  0.8571428571428571\n",
      "accracy_score corresponding to random state:  43  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  44  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  45  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  46  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  47  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  48  is:  0.8333333333333334\n",
      "accracy_score corresponding to random state:  49  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  50  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  51  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  52  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  53  is:  0.6428571428571429\n",
      "accracy_score corresponding to random state:  54  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  55  is:  0.8095238095238095\n",
      "accracy_score corresponding to random state:  56  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  57  is:  0.8571428571428571\n",
      "accracy_score corresponding to random state:  58  is:  0.8333333333333334\n",
      "accracy_score corresponding to random state:  59  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  60  is:  0.6666666666666666\n",
      "accracy_score corresponding to random state:  61  is:  0.6428571428571429\n",
      "accracy_score corresponding to random state:  62  is:  0.8095238095238095\n",
      "accracy_score corresponding to random state:  63  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  64  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  65  is:  0.6666666666666666\n",
      "accracy_score corresponding to random state:  66  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  67  is:  0.8333333333333334\n",
      "accracy_score corresponding to random state:  68  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  69  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  70  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  71  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  72  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  73  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  74  is:  0.8095238095238095\n",
      "accracy_score corresponding to random state:  75  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  76  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  77  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  78  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  79  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  80  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  81  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  82  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  83  is:  0.7142857142857143\n",
      "accracy_score corresponding to random state:  84  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  85  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  86  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  87  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  88  is:  0.7857142857142857\n",
      "accracy_score corresponding to random state:  89  is:  0.8571428571428571\n",
      "accracy_score corresponding to random state:  90  is:  0.6428571428571429\n",
      "accracy_score corresponding to random state:  91  is:  0.6428571428571429\n",
      "accracy_score corresponding to random state:  92  is:  0.8095238095238095\n",
      "accracy_score corresponding to random state:  93  is:  0.7380952380952381\n",
      "accracy_score corresponding to random state:  94  is:  0.6904761904761905\n",
      "accracy_score corresponding to random state:  95  is:  0.8095238095238095\n",
      "accracy_score corresponding to random state:  96  is:  0.7619047619047619\n",
      "accracy_score corresponding to random state:  97  is:  0.6428571428571429\n",
      "accracy_score corresponding to random state:  98  is:  0.8571428571428571\n",
      "accracy_score corresponding to random state:  99  is:  0.8333333333333334\n",
      "accracy_score corresponding to random state:  100  is:  0.8095238095238095\n",
      "\n",
      "\n",
      "max accuracy score corresponding to  42  is  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "max_r_score=0\n",
    "for r_state in range(42,101):\n",
    "    train_x, test_x,train_y, test_y = train_test_split(x, y,random_state = r_state,test_size=0.20)\n",
    "    lg=LogisticRegression()\n",
    "    lg.fit(train_x,train_y)\n",
    "    pred_y = lg.predict(test_x)\n",
    "    acc_scr=accuracy_score(test_y,pred_y)\n",
    "    print(\"accracy_score corresponding to random state: \",r_state,\" is: \",acc_scr)\n",
    "    if acc_scr>max_r_score:\n",
    "        max_r_score=acc_scr\n",
    "        final_r_state=r_state\n",
    "print()\n",
    "print()\n",
    "print(\"max accuracy score corresponding to \",final_r_state,\" is \",max_r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=.3, random_state=42)\n",
    "lg=LogisticRegression()\n",
    "lg.fit(train_x,train_y)\n",
    "pred_y = lg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8253968253968254\n",
      "Confusion Matrix: [[32  3]\n",
      " [ 8 20]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        35\n",
      "           1       0.87      0.71      0.78        28\n",
      "\n",
      "    accuracy                           0.83        63\n",
      "   macro avg       0.83      0.81      0.82        63\n",
      "weighted avg       0.83      0.83      0.82        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:', accuracy_score(test_y,pred))\n",
    "print('Confusion Matrix:', confusion_matrix(test_y,pred))   \n",
    "print('Classification Report:', classification_report(test_y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lg_sonar_data.pkl']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lg, 'lg_sonar_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
